{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick convention: \n",
    "# We work on a rectangular cell of side lengths a, b, c\n",
    "# This cuboid is in the positive coordinates and centered at 0\n",
    "# I.e. spanned by (a,0,0), (0,b,0) and (0,0,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating random points (optional)\n",
    "\n",
    "This function generates $N$ random points in a cell of sidelenghts $a,b,c$.  \n",
    "This is for demonstration and testing, but not an integral part of the software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_points(N=5,a=1,b=1,c=1):\n",
    "    \"\"\"\n",
    "    Generates N random points in [0,a]x[0,b]x[0,c] cuboid,\n",
    "    outputts Nx3 numpy array, each row containing x, y,z coordinates of a point.\n",
    "    \"\"\"\n",
    "    return np.array([[rd.random(),rd.random(),rd.random()] for i in range(N)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_points().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Creating periodic $\\alpha$-filtration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary functions for periodic_filtration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicating points to neighbouring cells\n",
    "Given points in a unit cell, this function duplicates them by translating to all neighbouring cells.  \n",
    "This is an auxiliary step to calculating the _periodic_ $\\alpha$-filtration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torus_copy(points, a=1,b=1,c=1):\n",
    "    \"\"\"\n",
    "    Takes numpy array points of N points on axbxc cube\n",
    "    and creates 8 copies surrounding it.\n",
    "    \n",
    "    Returns new_points, containing original points and 9+8+9=26 offset copies,\n",
    "    so Nx27 points in total.\n",
    "    \"\"\"\n",
    "    \n",
    "    N = np.shape(points)[0]\n",
    "    # first index  = which axbxc cuboid we are working on\n",
    "    # second index = index of corresponding original point\n",
    "    # third index  = x, y, z coordinates of point\n",
    "    new_points = np.zeros((27,N,3)) \n",
    "\n",
    "    i = 0 # to index the cuboid\n",
    "    for x in [-a,0,a]:\n",
    "        for y in [-b,0,b]:\n",
    "            for z in [-c,0,c]:\n",
    "            transl = np.array([[x,y,z] for dummy in range(N)])\n",
    "            new_points[i,:,:] = points + transl\n",
    "            i += 1\n",
    "            \n",
    "    return new_points.reshape(-1,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dim_split(filt):\n",
    "    \"\"\"\n",
    "    Takes list of simplices 'filt' with filtration values, \n",
    "    i.e. with elements ([3,2], 0.123)\n",
    "    Splits filt by dimension of elements.\n",
    "    Outputs the 4 seperate lists, one for each dimension 0 to 3.\n",
    "    \"\"\"\n",
    "    simp_0 = []\n",
    "    simp_1 = []\n",
    "    simp_2 = []\n",
    "    simp_3 = []\n",
    "    \n",
    "    for (simp, val) in filt:\n",
    "        p = len(simp)-1\n",
    "        \n",
    "        if p == 0:\n",
    "            simp_0.append((simp,val))\n",
    "        if p == 1:\n",
    "            simp_1.append((simp,val))\n",
    "        if p == 2:\n",
    "            simp_2.append((simp,val))\n",
    "        if p == 3:\n",
    "            simp_3.append((simp,val))\n",
    "    return simp_0, simp_1, simp_2, simp_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bound(point, a=1, b=1, c=1):\n",
    "    \"\"\"\n",
    "    Takes point with x,y,z coordinates.\n",
    "    Checks if point lies in cuboid [0,a) x [0,b) x [0,c).\n",
    "    If yes, outputs True, else False.\n",
    "    \"\"\"\n",
    "    x = point[0]\n",
    "    y = point[1]\n",
    "    z = point[2]\n",
    "    \n",
    "    return (    x >= 0 and x < a \n",
    "            and y >= 0 and y < b \n",
    "            and z >= 0 and z < 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equiv_num(x1,x2,m=1):\n",
    "    \"\"\"\n",
    "    Calculates 'x1-x2 mod m', where we always want to take \n",
    "    the representative with the smallest absolute value. \n",
    "    \"\"\"\n",
    "    z1 = abs((x1 - x2)%m)\n",
    "    z2 = abs(z1 - m)\n",
    "    return min(z1,z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identification_list(S0_list, S0, eps = 1e-5):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        S0_list ... naive filtration list  of 0-simplices ([3],3) as given by gudhi\n",
    "        S0      ... list of Simplex0D objects generated from S0\n",
    "\n",
    "    Output:\n",
    "        identify_list ... list of lists with entries [i,j], \n",
    "                           meaning that the ith vertex has to be matched to the jth Simplex0D object\n",
    "    \"\"\"\n",
    "    # build identification list for later reference when building higher simplices\n",
    "    identify_list = []\n",
    "\n",
    "    for i in range(len(S0_list)):\n",
    "        simp, filt_value = S0_list[i]\n",
    "        coord = np.array(alpha_complex.get_point(i))\n",
    "\n",
    "        for Simplex in S0: # looking for the point in the unit cell this corresponds to              \n",
    "            other_coord = Simplex.coords\n",
    "\n",
    "            if ((equiv_num(coord[0],other_coord[0],m=a)<eps) and \n",
    "                (equiv_num(coord[1],other_coord[1],m=b)<eps) and\n",
    "                (equiv_num(coord[2],other_coord[2],m=c)<eps)):\n",
    "\n",
    "                identify_index = Simplex.int_filt\n",
    "\n",
    "        identify_list.append([i, identify_index])\n",
    "    return identify_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "array = [2,-1,4,100,-1]\n",
    "ind1 = np.argmin(array)\n",
    "array.reverse()\n",
    "ind2 = len(array)-1-np.argmin(array)\n",
    "if ind1 == ind2:\n",
    "    print(\"first vertex is is v{ind1}\")\n",
    "else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_vertex(indices, coords):\n",
    "    \"\"\"\n",
    "    Takes two vertices and outputs them by lexicographical order.\n",
    "    \n",
    "    Input:\n",
    "        indices ... list [n0, n1], where ni is the integer filtration index of the ith vertex, identifying it uniquely \n",
    "        coords  ... list of lists [[x0, y0, z0], [x1, y1, z1]] containing the coordinates of both points.\n",
    "        \n",
    "    Output:\n",
    "        [nl, nr]   ... list of indices in lexicographical order\n",
    "        [xl,yl,zl] ... coordinates of left vertex\n",
    "        [xr,yr,zl] ... coordinates of right vertex \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    [n0, n1] = indices\n",
    "    [x0, y0, z0] = coords[0]\n",
    "    [x1, y1, z1] = coords[1]\n",
    "    \n",
    "    \n",
    "    if x0 < x1 or (x0 == x1 and y0 < y1) or (x0 == x1 and y0 == y1 and z0 < z1):\n",
    "        # 0 is left\n",
    "        left  = 0\n",
    "        right = 1\n",
    "\n",
    "    else:\n",
    "        # 1 is left\n",
    "        left  = 1\n",
    "        right = 0\n",
    "    \n",
    "    # left vertex\n",
    "    nl = indices[left]\n",
    "    xl = coord[left][0]\n",
    "    yl = coord[left][1]\n",
    "\n",
    "    # right vertex\n",
    "    nr = indices[right]\n",
    "    xr = coord[right][0]\n",
    "    yr = coord[right][1]\n",
    "    return [nl, nr], [xl,yl,zl], [xr,yr,zl]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of Simplex objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_S0(S0_list):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        S0_list ... List of 0-simplices as generated by gudhi, \n",
    "        after having split them by dimension\n",
    "    Output: \n",
    "        S0 ... List of Simplex0D objects containing the combinatorical representation,\n",
    "        the integer filtration value, the continuous filtration value \n",
    "        and the geometric coordinate of the point\n",
    "    \"\"\"\n",
    "\n",
    "    int_filt_value = 0\n",
    "    S0 = []\n",
    "\n",
    "    for i in range(len(simp0)):\n",
    "        simp, filt_value = simp0[i]\n",
    "\n",
    "        # check if 0-simplex lies in main cell\n",
    "        coord = alpha_complex.get_point(i)\n",
    "        if check_bound(coord,a=a,b=b,c=c): # point lies inside main cell\n",
    "            S0.append(sc.Simplex0D([int_filt_value], \n",
    "                                            int_filt_value, \n",
    "                                            filt_value, \n",
    "                                            coord))\n",
    "            int_filt_value +=1\n",
    "    return S0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_S1(S1_list, S0, alpha_complex, identify_list):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        Input:\n",
    "        S1_list ... List of 1-simplices as generated by gudhi, \n",
    "        after having split them by dimension\n",
    "        S0 ... List of Simplex0D objects of the filtration\n",
    "        alpha_complex ... alpha_complex objects as given by gudhi\n",
    "        identify_list ... identification list for periodically copied points as given by identification_list()\n",
    "        \n",
    "    Output: \n",
    "        S1 ... List of Simplex1D objects containing the combinatorical representation,\n",
    "        the integer filtration value, the continuous filtration value,\n",
    "        the crossing vector as numpy array and the vertices constituting the boundary\n",
    "        in lexicographical order\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # note that this is not the actual integer filtration value \n",
    "    # and this will get corrected later on\n",
    "    int_filt_value = len(S0) \n",
    "    S1 = []\n",
    "\n",
    "\n",
    "    for i in range(len(S1_list)):\n",
    "        \"\"\"\n",
    "        This does not work in 3d, because for a total order we need more than left-right\n",
    "        !!!!!!!\n",
    "        \"\"\"\n",
    "        simp, filt_value = S1_list[i]\n",
    "\n",
    "        # check what the leftmost vertex is\n",
    "        coord0 = alpha_complex.get_point(n0)\n",
    "        coord1 = alpha_complex.get_point(n1)\n",
    "\n",
    "        [nl, nr], coordl,  coordr = order_vertex(simp, [coord0, coord1])\n",
    "        \n",
    "        # Check if leftmost vertex is in unit cell\n",
    "        \"\"\"\n",
    "        function \"check_bound\" has been modified\n",
    "        this STILL needs to be adjusted here\n",
    "        also modify for 3d-version\n",
    "        \"\"\"\n",
    "        if check_bound(coordl, xmax=a, ymax=b):\n",
    "            # Calculate crossing vector\n",
    "            cross_vec = crossing_vector(coordr,xmax=a,ymax=b)\n",
    "\n",
    "            # identify the old vertices with the newly numerated ones!!!!! \n",
    "            # both for simplex, as well as for ordered vertices\n",
    "\n",
    "            nl_new = (identify_list[nl])[1]\n",
    "            nr_new = (identify_list[nr])[1]\n",
    "\n",
    "\n",
    "\n",
    "            lex_ordered_simp = [S0[nl_new], S0[nr_new]]\n",
    "            int_ordered_simp = sorted([nl_new,nr_new])\n",
    "\n",
    "            S1.append(sc.Simplex1D(int_ordered_simp, int_filt_value, filt_value, cross_vec,lex_ordered_simp))\n",
    "\n",
    "            int_filt_value +=1\n",
    "    return S1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_S2(S2_list, S1, alpha_complex, identify_list):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        Input:\n",
    "        S2_list ... List of 2-simplices as generated by gudhi, \n",
    "        after having split them by dimension\n",
    "        S1 ... List of Simplex1D objects of the filtration\n",
    "        alpha_complex ... alpha_complex objects as given by gudhi\n",
    "        identify_list ... identification list for periodically copied points as given by identification_list()\n",
    "        \n",
    "    Output: \n",
    "        S2 ... List of Simplex2D objects containing the combinatorical representation,\n",
    "        the integer filtration value, the continuous filtration value,\n",
    "        and the vertices constituting the boundary\n",
    "        in lexicographical order\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    !!! DESCIRPTION INCOMPLETE !!!\n",
    "    \"\"\"\n",
    "    \n",
    "    S2 = []\n",
    "    for i in range(len(S2_list)):\n",
    "            simp, filt_value = S2_list[i]\n",
    "\n",
    "            # how can we find the correct 2-simplices?\n",
    "\n",
    "            # if we have the vertices of the 2-simplex, we can look for 1-simplices which have two of these boundary points\n",
    "            # since we only keep 2-simplices with their left-most point in the main cell\n",
    "            # we can calculate the crossing vectors and then uniquly identify 2 out of 3 boundary elements\n",
    "\n",
    "            # for the last edge, we have to \n",
    "            # - take the middle and the rightmost point,\n",
    "            # - shift them such that the middle point is now in the main cell\n",
    "            # - calculate the crossing vector of these shifted points\n",
    "            # this is then the crossing vector of the last edge, and we can again identify\n",
    "            # the correct 1-simplex using the vertices and the crossing vector\n",
    "\n",
    "\n",
    "            [n1, n2, n3] = simp\n",
    "            coord1 = alpha_complex.get_point(n1)\n",
    "            coord2 = alpha_complex.get_point(n2)\n",
    "            coord3 = alpha_complex.get_point(n3)\n",
    "\n",
    "            # ordering vertices\n",
    "            a0 = n1\n",
    "            b0 = n2\n",
    "            c0 = n3\n",
    "            a0_coord = coord1\n",
    "            b0_coord = coord2\n",
    "            c0_coord = coord3\n",
    "\n",
    "            [a1,b1], a1_coord, b1_coord = order_vertex([a0,b0], [a0_coord, b0_coord])\n",
    "            [a2,c1], a2_coord, c1_coord = order_vertex([a1,c0], [a1_coord, c0_coord])\n",
    "            [b2,c2], b2_coord, c2_coord = order_vertex([b1,c1], [b1_coord, c1_coord])\n",
    "            \n",
    "            # a2 is the leftmost, b2 is the middle and c2 is the rightmost coordinate, \n",
    "            # or a2 < b2 < c2 in lexicographical order\n",
    "\n",
    "\n",
    "            # only if a2 is in the main cell do we continue\n",
    "            if check_bound(a2_coord, xmax=a, ymax=b): \n",
    "\n",
    "                # the vertices are not yet in the naming convention we have chosen\n",
    "                # so we rename them using identify_list\n",
    "                for i in range(len(identify_list)):\n",
    "                    new_name = (identify_list[i])[1]\n",
    "                    if i == a2:\n",
    "                        a2 = new_name\n",
    "                    if i == b2:\n",
    "                        b2 = new_name\n",
    "                    if i == c2:\n",
    "                        c2 = new_name\n",
    "\n",
    "\n",
    "                # first boundary element from a2 to b2\n",
    "                verts_1  = sorted([a2,b2])\n",
    "                cr_vec_1 = crossing_vector(b2_coord,xmax=a,ymax=b)\n",
    "\n",
    "                # second boundary element from a2 to c2\n",
    "                verts_2  = sorted([a2,c2])\n",
    "                cr_vec_2 = crossing_vector(c2_coord,xmax=a,ymax=b)\n",
    "\n",
    "                # third boundary element from b2 to c2\n",
    "                shift    = crossing_vector(b2_coord,xmax=a,ymax=b)\n",
    "                verts_3  = sorted([b2,c2])\n",
    "                cr_vec_3 = crossing_vector([c2_coord[0]-shift[0], c2_coord[1]-shift[1]])\n",
    "\n",
    "                for j in range(len(S1)):\n",
    "                    Simplex = S1[j]\n",
    "                    verts = Simplex.verts\n",
    "                    cv    = Simplex.cv\n",
    "\n",
    "\n",
    "                    if (verts[0] == verts_1[0]) and (verts[1] == verts_1[1]) and (np.linalg.norm(cv-cr_vec_1)<eps):\n",
    "                        bound_1 = Simplex\n",
    "                    if (verts[0] == verts_2[0]) and (verts[1] == verts_2[1]) and (np.linalg.norm(cv-cr_vec_2)<eps):\n",
    "                        bound_2 = Simplex\n",
    "                    if (verts[0] == verts_3[0]) and (verts[1] == verts_3[1]) and (np.linalg.norm(cv-cr_vec_3)<eps):\n",
    "                        bound_3 = Simplex\n",
    "\n",
    "                S2.append(sc.Simplex2D( sorted([a2,b2,c2]), int_filt_value, filt_value, [Simplices_0[a2],Simplices_0[b2],Simplices_0[c2]], [bound_1,bound_2,bound_3]))\n",
    "                int_filt_value += 1\n",
    "    return S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pfilt(S0,S1,S2,S3):\n",
    "    \"\"\"\n",
    "    Takes the lists of simplex objects Si and generates the \n",
    "    mixed-dimension periodic filtration, so with all the simplices, but only saved\n",
    "    through their vertices and their continuous filtration value.\n",
    "    \"\"\"\n",
    "\n",
    "    periodic_filt = []\n",
    "\n",
    "    periodic_filt_0 = [(Simplex.verts, Simplex.cont_filt) for Simplex in S0]\n",
    "    periodic_filt += periodic_filt_0\n",
    "\n",
    "    periodic_filt_1 = [(Simplex.verts, Simplex.cont_filt) for Simplex in S1]\n",
    "    periodic_filt += periodic_filt_1\n",
    "\n",
    "    periodic_filt_2 = [(Simplex.verts, Simplex.cont_filt) for Simplex in S2]\n",
    "    periodic_filt += periodic_filt_2\n",
    "\n",
    "    periodic_filt_3 = [(Simplex.verts, Simplex.cont_filt) for Simplex in S3]\n",
    "    periodic_filt += periodic_filt_3\n",
    "\n",
    "\n",
    "    periodic_filt.sort(key = lambda some_tuple: some_tuple[1])\n",
    "\n",
    "    return periodic_filt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_by_cont(S0,S1,S2,S3,periodic_filt):\n",
    "    \"\"\"\n",
    "    Since the integer filtration value is wrong (first storted by dimension, \n",
    "    only then by actuall filtration value), this needs to be reordered.\n",
    "    This function takes the Simplex, looks where it is in the periodic filtration,\n",
    "    and reassignes this placement. \n",
    "    \"\"\"\n",
    "    for Simplex in S0:\n",
    "        int_filt = periodic_filt.index((Simplex.verts, Simplex.cont_filt))\n",
    "        Simplex.update_int_filt(int_filt)\n",
    "    for Simplex in S1:\n",
    "        int_filt = periodic_filt.index((Simplex.verts, Simplex.cont_filt))\n",
    "        Simplex.update_int_filt(int_filt)\n",
    "    for Simplex in S2:\n",
    "        int_filt = periodic_filt.index((Simplex.verts, Simplex.cont_filt))\n",
    "        Simplex.update_int_filt(int_filt)\n",
    "    for Simplex in S3:\n",
    "        int_filt = periodic_filt.index((Simplex.verts, Simplex.cont_filt))\n",
    "        Simplex.update_int_filt(int_filt)\n",
    "    \"\"\"\n",
    "    !!!\n",
    "    I don't think that I even need a return statement here. \n",
    "    \"\"\"\n",
    "    return S0, S1, S2, S3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The final periodic_filtration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def periodic_filtration(points, max_alpha_square=float(\"inf\"), a=1, b=1, c=1):\n",
    "    \"\"\"\n",
    "    OLD:\n",
    "    Outputs\n",
    "        periodic_filt ... list of tuples, each tuple containing \n",
    "            1) simplex encoded as list of (periodically reduced) vertex numbers\n",
    "            2) filtration value as float\n",
    "        For example, periodic_filt[22] = ([8, 11], 0.0016)\n",
    "        \n",
    "        [Simplices_0, Simplices_1, Simplices_2, Simplices_3], where\n",
    "        Simplices_0 ... list of 0-simplices encoded as Simplex0D objects\n",
    "        Simplices_1 ... list of 1-simplices encoded as Simplex1D objects\n",
    "        Simplices_2 ... list of 2-simplices encoded as Simplex2D objects\n",
    "        Simplices_3 ... list of 3-simplices encoded as Simplex3D objects\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    Input:\n",
    "        a, b, c ... side lengths of cell [0,a] x [0,b] x [0,c]\n",
    "        points  ... numpy array of size (N,3) containing N points in cell\n",
    "        max_alpha_square   ... maximum alpha (squared) value of alpha-filtration\n",
    "        \n",
    "    Output:\n",
    "        XXXXXX\n",
    "    \"\"\"\n",
    "    N = points.shape[0]\n",
    "    points_dup = torus_copy(points)\n",
    "    \n",
    "    # alpha-complex generation by gudhi\n",
    "    alpha_complex = gd.AlphaComplex(points_dup)\n",
    "    simplex_tree = alpha_complex.create_simplex_tree(max_alpha_square=max_alpha_square)\n",
    "    filtration = simplex_tree.get_filtration()   \n",
    "    \n",
    "    # split unidentified simplices by dimension\n",
    "    simp0, simp1, simp2, simp3 = dim_split(filtration)\n",
    "    \n",
    " \n",
    "    \n",
    "    Simplices_3 = []\n",
    "    \n",
    "    \"\"\"\n",
    "    I removed the connected component list because I want to generate this as a method later,\n",
    "    not at initialisation. \n",
    "    However, this STILL NEEDS TO BE DONE!!!\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 0-Simplices ---------------------------------\n",
    "    S0 = create_S0(simp0)\n",
    "    identify_list = identification_list(S0_list=simp0, S0=S0, eps = 1e-5)\n",
    "\n",
    "    \n",
    "    # 1-Simplices ---------------------------------\n",
    "    S1 = create_S1(S1_list=simp1, S0=S0, alpha_complex=alpha_complex, identify_list=identify_list)\n",
    "\n",
    "    \n",
    "    \n",
    "    # 2-Simplices ---------------------------------\n",
    "    S2 = create_S2(S2_list=simp2, S1=S1, alpha_complex=alpha_complex, identify_list=identify_list)\n",
    "    \n",
    "    # 3-Simplices\n",
    "    \"\"\"\n",
    "    THIS NEEDS TO BE CREATED\n",
    "    \"\"\"\n",
    "\n",
    "    periodic_filt = generate_pfilt(S0=S0,S1=S1,S2=S2,S3=S3)\n",
    "    \n",
    " \n",
    "    S0, S1, S2, S3 = reorder_by_cont(S0=S0,S1=S1,S2=S2,S3=S3, periodic_filt=periodic_filt)\n",
    "    \"\"\"\n",
    "    If I don't need a return statement, this would also not need an assignment. \n",
    "    See the original definition of the function. \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    \n",
    "    return periodic_filt, [S0, S1, S2, S3]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating PPH\n",
    "\n",
    "After the calculation of the periodic filtration, next comes calculating the periodic persistent homology. The algorithm here should not differ significantly from the standard ones. The only reason we are writing this from scratch is that pre-existing software is not made to handle our data, especialy in case of degenerate simplices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary functions for PH()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_matrix(S):\n",
    "    \"\"\"\n",
    "    Takes list of subslists of Simplix type objects.\n",
    "    Outputs a boundary matrix as numpy matrix.\n",
    "    \n",
    "    Note that the boundary matrix is sorted by dimension (their index in S[i]), not as given by .int_filt\n",
    "    \"\"\"\n",
    "    S0, S1, S2, S3 = S\n",
    "    \n",
    "    # Initialise matrix of dimension s0+s1+s2(boundaries) x s1+s2+s3\n",
    "    D = np.zeros((len(S0+S1+S2),len(S0+S1+S2+S3)))\n",
    "    \n",
    "    # The 0-Simplices all appear at the beginning and are already ordered by their usual index\n",
    "    \"\"\"\n",
    "    ???\n",
    "    instead of extracting Si, defining di and calculating D per dimension, \n",
    "    can't we do all of this in one go using indices?\n",
    "    \"\"\"\n",
    "    d0 = len(S0)\n",
    "    d1 = len(S1)\n",
    "    d2 = len(S2)\n",
    "    \n",
    "    for j in range(d1):\n",
    "        for i in S1[j].verts:\n",
    "            D[i,j+d0] += 1\n",
    "    \n",
    "    for j in range(d2):\n",
    "        for i in range(d1):\n",
    "            if S1[i] in S2[j].boundary:\n",
    "                D[i+d0,j+d0+d1] += 1\n",
    "    \n",
    "    \"\"\"\n",
    "    ???\n",
    "    The 3rd boundary matrix is missing at this point. Process should be the same, though.\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.mod(D,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_low(column):\n",
    "    \"\"\" \n",
    "    Takes a column i.e. numpy 1dim array. \n",
    "    Outputs the index of the lowest non-zero element of the given column.\n",
    "    If the column is all zero, it returns -1.\n",
    "    \"\"\"\n",
    "    low = -1\n",
    "    m = len(column)\n",
    "    for i in range(0,m):\n",
    "        if column[m-1-i]==1:\n",
    "            low = m-1-i\n",
    "            break\n",
    "    return low\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_red(D, exhaustive=False): \n",
    "    \"\"\"\n",
    "    Takes a binary boundary matrix and performs column reduction on it.\n",
    "    Returns the reduced matrix \"R\", as well as a list of its pivot elements \"pivots\". \n",
    "    Zero columns are encoded in pivots as -1. \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    !!!!\n",
    "    We want to implement exhaustive reduction at some point. \n",
    "    \"\"\"\n",
    "    # D is numpy array of size mxn\n",
    "    (m,n) =  D.shape # rows, column\n",
    "    R = D.copy()\n",
    "    V = np.identity(n)\n",
    "    \n",
    "    pivots = []\n",
    "    \n",
    "    for i in range(0,n):\n",
    "        # look at current pivot \n",
    "        low = check_low(R[:,i])\n",
    "        \n",
    "        # check if this is already a pivot element\n",
    "        while (low in pivots) and (low != -1): \n",
    "            # while pivot is taken, perform matrix reduction on R\n",
    "            \n",
    "            j = pivots.index(low)\n",
    "            R[:,i]= (R[:,i] + R[:,j]) % 2\n",
    "            V[:,i]= (V[:,i] + V[:,j]) % 2\n",
    "            \n",
    "            # get new pivot\n",
    "            low = check_low(R[:,i]) \n",
    "            \n",
    "           \n",
    "            # don't forget to reduce mod 2\n",
    "        \n",
    "        pivots.append(low)\n",
    "        \n",
    "    \n",
    "    return pivots, R, V\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_groups(dim_list, pivots):\n",
    "    dCn = np.zeros(d+1)\n",
    "    dZn = np.zeros(d+1)\n",
    "    dBn = np.zeros(d+1)\n",
    "    dHn = np.zeros(d+1)\n",
    "\n",
    "    # Calculate the vector space dimensions, in particular Betti numbers\n",
    "    m = 0\n",
    "    for i in range(0,d+1):\n",
    "        # extract dimensions of vector spaces\n",
    "        dCn[i]   = dim_list[i]\n",
    "        dZn[i]   = pivots[m:m+dim_list[i]].count(-1)\n",
    "        dBn[i-1] = dCn[i] - dZn[i]\n",
    "        m += dim_list[i]\n",
    "\n",
    "    for i in range(0,d+1):\n",
    "        dHn[i]   = dZn[i] - dBn[i]\n",
    "\n",
    "    return dCn, dZn, dBn, dHn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pps(D, dim_list, S):\n",
    "\n",
    "    pp_int = [] # list of persistence pairs\n",
    "\n",
    "    # calculate persistence pairs\n",
    "    for j in range(D.shape[1]):# looking at the jth column\n",
    "\n",
    "        # determine dimension\n",
    "        for k in range(len(dim_list)): \n",
    "                if j < sum(dim_list[0:k+1]) and j >= sum(dim_list[0:k]):\n",
    "                    dim = k\n",
    "        \"\"\"\n",
    "        Here we are again taking the numbering first by dimension, then by filtration.\n",
    "        We need to reference the actuall int_filt of the respective simplices. \n",
    "        This should work by looking at the jth k-simplex and taking its int_filt value.\n",
    "        \"\"\"\n",
    "        # if jth column is 0 --> new cycle\n",
    "        if pivots[j] == -1:\n",
    "            pds = sum([len(S[cnt]) for cnt in range(dim)]) # previous dimension needed to be subtracted \n",
    "            a = (S[dim])[j-pds].int_filt\n",
    "            pp_int.append((dim, (a,inf)))\n",
    "\n",
    "        # if column is non-zero --> death of class (that must have been born previously)\n",
    "        else:\n",
    "            pds1 = sum([len(S[cnt]) for cnt in range(dim)]) # previous dimension needed to be subtracted \n",
    "            pds2 = sum([len(S[cnt]) for cnt in range(max(0,dim-1))])  # previous dimension needed to be subtracted \n",
    "\n",
    "            a = (S[dim-1])[pivots[j]-pds2].int_filt\n",
    "            b = (S[dim])[j-pds1].int_filt\n",
    "            pp_int.remove((dim-1, (a, inf)))\n",
    "            pp_int.append((dim-1, (a,b)))\n",
    "\n",
    "\n",
    "    # sort by beginning of interval\n",
    "    firstof = lambda l: (l[1])[0]\n",
    "    pp_int.sort(key=firstof)\n",
    "\n",
    "    return pp_int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representatives(V, pp_int, pp_cont, S):\n",
    "    \"\"\"\n",
    "    Takes a matrix V as given by column_red(), \n",
    "    persistence pairs pp_int with integer filtration values\n",
    "    persistence pairs pp_cont with continuous filtration values\n",
    "    and a list S of sublists S[i] each containing Simplex type objects. \n",
    "    \n",
    "    Returns a list rep_list of Persistence_Pair objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    # The j-th column of V encodes the columns in ∂ that add up to give the j-th column in R.  (p. 182 / 194)\n",
    "    m,n = V.shape\n",
    "    rep_list = []\n",
    "    \n",
    "    \n",
    "    for index in range(len(pp_int)):\n",
    "        (dim,(a,b)) = pp_int[index]\n",
    "        (dim,(a_cont,b_cont)) = pp_cont[index]\n",
    "        \n",
    "        \n",
    "        for i in range(len(S[dim])):\n",
    "            if S[dim][i].int_filt == a:\n",
    "                j = i\n",
    "                break\n",
    "                \n",
    "        pds = sum([len(S[cnt]) for cnt in range(dim)])\n",
    "        j += pds\n",
    "        \n",
    "        # We want to take the birth representative,\n",
    "        # meaning we look at the column of the cycle being born\n",
    "        \n",
    "        jcolumn = V[:,j]\n",
    "        reps = []\n",
    "        \n",
    "        for i in range(0,m): \n",
    "            if jcolumn[i] == 1: \n",
    "                S_index = i - pds\n",
    "                Simplex = S[dim][S_index] \n",
    "                reps.append(Simplex)\n",
    "        \n",
    "        rep_list.append(sc.Persistence_Pair(dim, (a,b), (a_cont,b_cont), reps))\n",
    "    \n",
    "    \n",
    "\n",
    "    return rep_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc2cont_pp(pp, filt):\n",
    "    \"\"\"\n",
    "    Takes the list of persistence pairs with discrete filtration values, as well as the original filtration,\n",
    "    and outputs a list of peristence pairs with their smooth filtration values. \n",
    "    \"\"\"\n",
    "    pp_cont = []\n",
    "    for (dim, (a,b)) in pp:\n",
    "        a_cont = (filt[a])[1]\n",
    "        \n",
    "        if b != float(\"inf\"):\n",
    "            b_cont = (filt[b])[1]\n",
    "        else:\n",
    "            b_cont = float(\"inf\")\n",
    "            \n",
    "        pp_cont.append((dim, (a_cont, b_cont)))\n",
    "        \n",
    "    return pp_cont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The final PH()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PH(filt, S):\n",
    "    \"\"\"\n",
    "    Takes list \"filt\" of naive filtration with continuous filtration values and\n",
    "    list \"S\" containing sublists of Simplex type objects, sorted by dimension\n",
    "    \n",
    "    Returns the dimensions of Cn, Bn, Zn and Hn, \n",
    "    as well as persistence pairs \"pp\" and representatives \"reps\" of homology classes.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    d=2 # this is the dimension we are working in\n",
    "        # right now we are only on the square, so d=2\n",
    "    \n",
    "    D = boundary_matrix(S)\n",
    "    \n",
    "    dim_list = [len(S[i]) for i in range(0,d+1)]\n",
    "    \n",
    "    \n",
    "    pivots, R, V = column_red(D)\n",
    "    \n",
    "    \n",
    "    \n",
    "    inf = float('inf')\n",
    "    \n",
    "\n",
    "    dCn, dZn, dBn, dHn = calc_groups(dim_list, pivots)\n",
    "    \n",
    "    \n",
    "\n",
    "    pp_int = calc_pps(D, dim_list, S)\n",
    "    \n",
    "    \n",
    "    # persistance pairs with continuous values\n",
    "    pp_cont = disc2cont_pp(pp_int, filt)\n",
    "\n",
    "    # Caculate representatives (contains also information of pp_int and pp_cont)\n",
    "    pairs_w_reps = representatives(V, pp_int, pp_cont, S) \n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "    for timestep in range(len(filt)):\n",
    "        for v in S[0]:\n",
    "            v.calc_cc(S, timestep)\n",
    "    \n",
    "    \n",
    "    return dCn, dZn, dBn, dHn, pp_int, pp_cont, pairs_w_reps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the evolution $\\Lambda_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary functions for Lambda_0_evolution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_vol_3d(matrix_np):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes 3x3 numpy array containing 3 column vectors, \n",
    "    of which either p = 0, 1, 2 or 3 are linearly independant.\n",
    "    Returns the p-dimensional volume the column vectors span, as well as the dimension p.\n",
    "    \"\"\"\n",
    "    matrix = sp.Matrix(matrix_np)\n",
    "    mat_red, pivots = matrix.T.rref()\n",
    "    mat_red=mat_red.T\n",
    "    p = len(pivots)\n",
    "    \n",
    "    if   p==0:\n",
    "        det_p = 1\n",
    "    \n",
    "    elif p==1:\n",
    "        #print(\"pivots:\")\n",
    "        #print(pivots)\n",
    "        #print(\"reduced matrix:\")\n",
    "        #sp.pprint(mat_red)\n",
    "        det_p = mat_red[:,0].norm()\n",
    "    \n",
    "    elif p==2:\n",
    "        \"\"\"\n",
    "        !!!\n",
    "        Take norm of cross product of the two reduced vectors\n",
    "        !!!\n",
    "        \"\"\"\n",
    "        \n",
    "    elif p==3:\n",
    "        det_p = la.det(matrix_np)\n",
    "        \n",
    "        \n",
    "    return abs(det_p), p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The final Lambda_0_evolution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lambda_0_evolution(p_filt, N, pairs_w_reps):\n",
    "    \"\"\"\n",
    "    Takes naive filtration p_filt, \n",
    "    number of original connected components (number of 0-Simplices) N, \n",
    "    and list of persistence pairs pairs_w_reps.\n",
    "    \n",
    "    Returns numpy array time_list of size (len(p_filt), N, 2, 2),\n",
    "    where the first index is the integer filtration step,\n",
    "    the second index is the connected component,\n",
    "    and the leftover 2x2 matrix is the basis spanning Lambda_0 of this connected component at a given timestep. \n",
    "    \"\"\"\n",
    "\n",
    "    # Make list of lists\n",
    "    # First index gives timestep\n",
    "    # Second index gives connected component (0 to N-1)\n",
    "    # This then contains all the vectors contributing to this connected component. \n",
    "    from Reduce2IntegerBasis import reduce_spanning_set_2d as rss2\n",
    "    #rss2 = reload(rss2)\n",
    "\n",
    "    #time_list = [[[] for j in range(N)] for i in range(len(p_filt))]\n",
    "    time_list = [[np.zeros((2,2),dtype=np.int32) for j in range(N)] for i in range(len(p_filt))]\n",
    "    time_list = np.zeros((len(p_filt),N,2,2),dtype=np.int32)\n",
    "    # We need to calculate the connected components .cc for each pair in pairs_w_reps at each timestep i. \n",
    "    # At this point we do not save a list of these connected components for each timestep\n",
    "    # rather we look at some simplex that forms the cacly of the representative pair and look at its cc. \n",
    "    # this way we only have little computational work whenever we need to look this up\n",
    "    # however, in a case such as here where we want to have this information at any given timestep\n",
    "    # it might be easier to just calculate the cc's once and save them (?)\n",
    "\n",
    "\n",
    "    for t in range(len(p_filt)):\n",
    "        # we are at timestep \"t\"\n",
    "        span_set_list = [[] for j in range(N)] # one list for each cc\n",
    "        for pair in pairs_w_reps:\n",
    "            # we look at persistence pair \"pair\"\n",
    "            if pair.dim == 1 and pair.start_int <= t and pair.end_int > t:\n",
    "                # if this persistence pair is of dimension 1 (1-homology), \n",
    "                # has been born before t and will die after t\n",
    "                # (i.e. it is alive at time t)\n",
    "                # then its crossing vector contributes to the crossing vectors \n",
    "                # of its connected component at time t\n",
    "                pair.calc_cc() # calculate the connected component of pair\n",
    "                cc = pair.cc[t]\n",
    "                #(time_list[time])[cc].append(pair.return_cv(time))\n",
    "                new_cv = pair.return_cv(t)\n",
    "                if abs(la.norm(new_cv))>0.9:\n",
    "                    # check if new vector is noan-trivial before calling the basis reduction function\n",
    "                    span_set_list[cc] = rss2(span_set_list[cc],new_cv)\n",
    "\n",
    "        for comp in range(N):\n",
    "            for i in range(len(span_set_list[comp])):\n",
    "                time_list[t][comp][:,i] = span_set_list[comp][i]\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    for t in range(N,len(p_filt)):\n",
    "        print(f\"\\ntime {t}:\")\n",
    "        for comp in range(N):\n",
    "            print(f\"Component {comp} -- Lambda_0 spanned by: {(time_list[t])[comp]}\")\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    return time_list\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
